{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-12T06:01:26.314995Z","iopub.execute_input":"2023-11-12T06:01:26.315468Z","iopub.status.idle":"2023-11-12T06:01:26.329608Z","shell.execute_reply.started":"2023-11-12T06:01:26.315439Z","shell.execute_reply":"2023-11-12T06:01:26.328388Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/input/malayalam-news/HackFake Database for the Hackathon - Sheet1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nimport matplotlib.pyplot as plt\ntf.get_logger().setLevel('ERROR')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:26.331927Z","iopub.execute_input":"2023-11-12T06:01:26.332983Z","iopub.status.idle":"2023-11-12T06:01:26.340679Z","shell.execute_reply.started":"2023-11-12T06:01:26.332929Z","shell.execute_reply":"2023-11-12T06:01:26.339852Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Read dataset\nFILEPATH='/kaggle/input/malayalam-news'\ndf_train=pd.read_csv(os.path.join(FILEPATH,'HackFake Database for the Hackathon - Sheet1.csv'))[:500]\ndf_train = df_train.drop(['Website (source)', 'Timeline/Date','Title'], axis=1)[2:].reset_index(drop=True)\ndf_train=df_train.dropna(axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:26.341855Z","iopub.execute_input":"2023-11-12T06:01:26.342205Z","iopub.status.idle":"2023-11-12T06:01:26.603414Z","shell.execute_reply.started":"2023-11-12T06:01:26.342172Z","shell.execute_reply":"2023-11-12T06:01:26.601277Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:26.606328Z","iopub.execute_input":"2023-11-12T06:01:26.606723Z","iopub.status.idle":"2023-11-12T06:01:26.617196Z","shell.execute_reply.started":"2023-11-12T06:01:26.606690Z","shell.execute_reply":"2023-11-12T06:01:26.615112Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Index(['Heading of News Article', 'Text of News Article', 'Hate speech',\n       'Misleading', 'Disinformation', 'Rumor/Hoax', 'Sensationalism',\n       'Credible'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"X=df_train[['Text of News Article','Heading of News Article']]\n#'Heading of News Article'\ny=df_train[['Hate speech','Misleading','Disinformation','Rumor/Hoax','Sensationalism']]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\ny_train=np.array(y_train).astype('int')\ny_test=np.array(y_test).astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:26.619302Z","iopub.execute_input":"2023-11-12T06:01:26.619860Z","iopub.status.idle":"2023-11-12T06:01:26.639528Z","shell.execute_reply.started":"2023-11-12T06:01:26.619820Z","shell.execute_reply":"2023-11-12T06:01:26.637681Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import regularizers,layers,Input,Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import TextVectorization,Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, BatchNormalization, Dropout\n\n#Custom CallBack and Scheduler\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    patience=15,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nlr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n  0.001,\n  decay_steps=X.shape[0]*20,\n  decay_rate=1,\n  staircase=False)\n\n\ndef tf_model():\n    # Input layers for two text columns\n    input_layer1 = Input(shape=(), dtype=tf.string, name='text_input1')\n    input_layer2 = Input(shape=(), dtype=tf.string, name='text_input2')\n\n    # Preprocessor layers for each text column\n    preprocessor_layer = hub.KerasLayer(\n        \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\"\n    )\n    \n    preprocessed_text1 = preprocessor_layer(input_layer1)\n    preprocessed_text2 = preprocessor_layer(input_layer2)\n\n    # Encoder layers for each text column\n    encoder_layer = hub.KerasLayer(\n        \"https://tfhub.dev/google/LaBSE/2\",\n        trainable=False\n    )\n\n    embedded_text1 = encoder_layer(preprocessed_text1)[\"sequence_output\"]\n    embedded_text2 = encoder_layer(preprocessed_text2)[\"sequence_output\"]\n\n    # Concatenate the outputs of the two text columns\n    concatenated_output = layers.Concatenate()([embedded_text1, embedded_text2])\n\n    # Pass the concatenated embeddings through LSTM layer\n    lstm_layer = tf.keras.layers.LSTM(units=64, return_sequences=False)\n    lstm_output = lstm_layer(concatenated_output)\n\n    # For example, add a Dense layer for classification\n    output_layer = layers.Dense(units=5, activation='sigmoid', name='output')(lstm_output)\n\n    # Create the model with two input layers\n    model = Model(inputs=[input_layer1, input_layer2], outputs=output_layer)\n\n    return model\n\n# Create the model\nmodel = tf_model()\n\n# Display the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:26.641227Z","iopub.execute_input":"2023-11-12T06:01:26.642528Z","iopub.status.idle":"2023-11-12T06:01:42.066224Z","shell.execute_reply.started":"2023-11-12T06:01:26.642474Z","shell.execute_reply":"2023-11-12T06:01:42.062985Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n text_input1 (InputLayer)    [(None,)]                    0         []                            \n                                                                                                  \n text_input2 (InputLayer)    [(None,)]                    0         []                            \n                                                                                                  \n keras_layer_2 (KerasLayer)  {'input_mask': (None, 128)   0         ['text_input1[0][0]',         \n                             , 'input_type_ids': (None,              'text_input2[0][0]']         \n                              128),                                                               \n                              'input_word_ids': (None,                                            \n                             128)}                                                                \n                                                                                                  \n keras_layer_3 (KerasLayer)  {'sequence_output': (None,   4709268   ['keras_layer_2[0][0]',       \n                              128, 768),                  49         'keras_layer_2[0][1]',       \n                              'encoder_outputs': [(None              'keras_layer_2[0][2]',       \n                             , 128, 768),                            'keras_layer_2[1][0]',       \n                              (None, 128, 768),                      'keras_layer_2[1][1]',       \n                              (None, 128, 768),                      'keras_layer_2[1][2]']       \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768),                                                   \n                              (None, 128, 768)],                                                  \n                              'default': (None, 768),                                             \n                              'pooled_output': (None, 7                                           \n                             68)}                                                                 \n                                                                                                  \n concatenate_1 (Concatenate  (None, 128, 1536)            0         ['keras_layer_3[0][14]',      \n )                                                                   'keras_layer_3[1][14]']      \n                                                                                                  \n lstm_1 (LSTM)               (None, 64)                   409856    ['concatenate_1[0][0]']       \n                                                                                                  \n output (Dense)              (None, 5)                    325       ['lstm_1[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 471337030 (1.76 GB)\nTrainable params: 410181 (1.56 MB)\nNon-trainable params: 470926849 (1.75 GB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss='binary_crossentropy',\n        metrics=['acc']\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:42.070424Z","iopub.execute_input":"2023-11-12T06:01:42.072148Z","iopub.status.idle":"2023-11-12T06:01:42.099100Z","shell.execute_reply.started":"2023-11-12T06:01:42.072060Z","shell.execute_reply":"2023-11-12T06:01:42.096564Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"a0,a1=X_train['Text of News Article'],X_train['Heading of News Article']\nb0,b1=X_test['Text of News Article'],X_test['Heading of News Article']","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:42.107705Z","iopub.execute_input":"2023-11-12T06:01:42.108278Z","iopub.status.idle":"2023-11-12T06:01:42.118343Z","shell.execute_reply.started":"2023-11-12T06:01:42.108233Z","shell.execute_reply":"2023-11-12T06:01:42.116115Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.fit([a0,a1],y_train,epochs=7,callbacks=[early_stopping],validation_data=[[b0,b1],y_test],batch_size=200)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T06:01:42.120357Z","iopub.execute_input":"2023-11-12T06:01:42.120786Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/7\n2/2 [==============================] - 181s 101s/step - loss: 0.7380 - acc: 0.1386 - val_loss: 0.6243 - val_acc: 0.2364\nEpoch 2/7\n","output_type":"stream"}]}]}